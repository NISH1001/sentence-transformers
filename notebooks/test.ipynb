{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef2c3644-59e2-404c-9475-8f854c25ab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50a6d022-2f6a-433c-b3c4-deaa87f3ca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d10c88c-3cc9-4b77-926f-d355c81c99c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba5dd556-74f6-4db7-842f-9c3c7d82592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentform.modeling import SentenceTransformer\n",
    "from sentform.pooling import MeanPooling\n",
    "from sentform.utils import pairwise_cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5d4ba8-9da4-4449-8f3f-8212ae2ece12",
   "metadata": {},
   "source": [
    "# Sanity-check SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc4bbca3-9ae5-40fb-808b-e78dddf5f065",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = AutoModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd08d871-d3f5-404c-8ba1-01bccc94c629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/npantha/dev/nish/projects/sentence-transformers/venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sentformer = SentenceTransformer(\n",
    "    backbone=backbone,\n",
    "    pooling_layer=MeanPooling()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12a3ed2c-bd33-4642-8bec-432a0b6ec455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (backbone): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (pooling): MeanPooling()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54e73097-a75a-4fd9-ae33-4d77a8a038c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentformer.embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "935ee134-a820-46bc-904c-dd25d46d68d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"I love cat.\",\n",
    "    \"I prefer dogs.\",\n",
    "    \"I didn't like that movie.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb4a6407-1b99-45d1-a213-2fcb1a7bd926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 768])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = sentformer.encode(sentences)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "daafe767-de13-49ab-b4f9-99756c502564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.7155, 0.6561],\n",
       "        [0.7155, 1.0000, 0.6478],\n",
       "        [0.6561, 0.6478, 1.0000]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_cosine_similarity(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33537ed8-a640-4c2a-b259-27baa2c7a3e9",
   "metadata": {},
   "source": [
    "# Sanity-Check Multi-Task learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a3455be-951c-4b4b-abe1-2e7064cb5b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentform.modeling import MultiTaskFormer\n",
    "from sentform.heads import ClassificationHead, NERHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6223278-1413-4d4a-94fb-c87f235919cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/npantha/dev/nish/projects/sentence-transformers/venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "multi_tasker = MultiTaskFormer(\n",
    "    heads=[\n",
    "        ClassificationHead(\n",
    "            backbone.config.hidden_size,\n",
    "            num_classes=3,\n",
    "            labels=[\"A\", \"B\", \"C\"],\n",
    "            multi_label=False\n",
    "        ),\n",
    "        NERHead(\n",
    "            backbone.config.hidden_size,\n",
    "            num_tags=3,\n",
    "            ner_tags=[\"Entity1\", \"Entity2\", \"Entity2\"],\n",
    "            multi_label=False\n",
    "        )\n",
    "    ],\n",
    "    backbone=backbone,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c857fab-a9a6-42b5-8912-bc3c71f6cbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = multi_tasker(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91f576a0-c774-4685-870d-b65d89d5492f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'head_0': {'logits': tensor([[-0.1184, -0.1660,  0.2809],\n",
       "          [-0.0499, -0.0170,  0.3292],\n",
       "          [ 0.1075, -0.0941,  0.2124]]),\n",
       "  'predicted_labels': ['C', 'C', 'C']},\n",
       " 'head_1': {'logits': tensor([[[ 0.0434,  0.2204,  0.5106],\n",
       "           [ 0.1505,  0.5894,  0.2920],\n",
       "           [-0.0443,  0.2464,  0.2912],\n",
       "           [ 0.1045,  0.5564,  0.5694],\n",
       "           [ 0.0764,  0.6265,  0.1294],\n",
       "           [ 0.2616, -0.1412, -0.1685],\n",
       "           [ 0.0261,  0.5208,  0.1622],\n",
       "           [ 0.1476,  0.6539,  0.2159],\n",
       "           [ 0.0511,  0.5468,  0.2664],\n",
       "           [ 0.2583,  0.7474,  0.2863]],\n",
       "  \n",
       "          [[ 0.0248, -0.0257,  0.4707],\n",
       "           [-0.0033,  0.3054,  0.1180],\n",
       "           [-0.2258, -0.1988,  0.1635],\n",
       "           [ 0.1792,  0.0022,  0.8497],\n",
       "           [ 0.1765,  0.3426, -0.2418],\n",
       "           [ 0.1304, -0.1063, -0.3706],\n",
       "           [ 0.0858,  0.3002,  0.1983],\n",
       "           [ 0.1181,  0.3982,  0.2706],\n",
       "           [ 0.0992,  0.2153,  0.2534],\n",
       "           [ 0.2846,  0.6430,  0.3579]],\n",
       "  \n",
       "          [[ 0.2011,  0.0018,  0.4207],\n",
       "           [ 0.2311,  0.1977, -0.1258],\n",
       "           [ 0.3646, -0.2941, -0.2840],\n",
       "           [ 0.4075, -0.2553, -0.6478],\n",
       "           [ 0.2947,  0.0307, -0.0897],\n",
       "           [-0.1847,  0.2703,  0.1071],\n",
       "           [ 0.1859,  0.2274, -0.1194],\n",
       "           [-0.0661,  0.1314, -0.0391],\n",
       "           [ 0.3146,  0.1062, -0.4159],\n",
       "           [ 0.0072, -0.2552, -0.1818]]]),\n",
       "  'predicted_labels': [['Entity2',\n",
       "    'Entity2',\n",
       "    'Entity2',\n",
       "    'Entity2',\n",
       "    'Entity2',\n",
       "    'Entity1',\n",
       "    'Entity2',\n",
       "    'Entity2',\n",
       "    'Entity2',\n",
       "    'Entity2'],\n",
       "   ['Entity2',\n",
       "    'Entity2',\n",
       "    'Entity2',\n",
       "    'Entity2',\n",
       "    'Entity2',\n",
       "    'Entity1',\n",
       "    'Entity2',\n",
       "    'Entity2',\n",
       "    'Entity2',\n",
       "    'Entity2'],\n",
       "   ['Entity2',\n",
       "    'Entity1',\n",
       "    'Entity1',\n",
       "    'Entity1',\n",
       "    'Entity1',\n",
       "    'Entity2',\n",
       "    'Entity2',\n",
       "    'Entity2',\n",
       "    'Entity1',\n",
       "    'Entity1']]}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1111e27d-8bb6-42fd-ac7f-388e4a699dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head_0 torch.Size([3, 3])\n",
      "['C', 'C', 'C']\n",
      "----------\n",
      "head_1 torch.Size([3, 10, 3])\n",
      "[['Entity2',\n",
      "  'Entity2',\n",
      "  'Entity2',\n",
      "  'Entity2',\n",
      "  'Entity2',\n",
      "  'Entity1',\n",
      "  'Entity2',\n",
      "  'Entity2',\n",
      "  'Entity2',\n",
      "  'Entity2'],\n",
      " ['Entity2',\n",
      "  'Entity2',\n",
      "  'Entity2',\n",
      "  'Entity2',\n",
      "  'Entity2',\n",
      "  'Entity1',\n",
      "  'Entity2',\n",
      "  'Entity2',\n",
      "  'Entity2',\n",
      "  'Entity2'],\n",
      " ['Entity2',\n",
      "  'Entity1',\n",
      "  'Entity1',\n",
      "  'Entity1',\n",
      "  'Entity1',\n",
      "  'Entity2',\n",
      "  'Entity2',\n",
      "  'Entity2',\n",
      "  'Entity1',\n",
      "  'Entity1']]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for idx, out in outputs.items():\n",
    "    print(idx, out[\"logits\"].shape)\n",
    "    pprint(out[\"predicted_labels\"])\n",
    "    print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f705cc-52e0-4eaf-8146-31f0123fda32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
